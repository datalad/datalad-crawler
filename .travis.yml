# vim ft=yaml
# travis-ci.org definition for DataLad build
language: python

python:
  - 2.7

cache:
  - apt

env:
  global:
    # will be used in the matrix, where neither other variable is used
    - BOTO_CONFIG=/tmp/nowhere
    - DATALAD_TESTS_SSH=1
    - DATALAD_LOG_CMD_ENV=GIT_SSH_COMMAND
    - TESTS_TO_PERFORM=
    - NOSE_OPTS=-s
    #- NOSE_SELECTION_OP="not "   # so it would be "not (integration or usecase)"
    # Special settings/helper for combined coverage from special remotes execution
    - COVERAGE=coverage
    - DATALAD_DATASETS_TOPURL=http://datasets-tests.datalad.org
  matrix:
    - DATALAD_REPO_VERSION=5


before_install:
  # Just in case we need to check if nfs is there etc
  - sudo lsmod
  # The ultimate one-liner setup for NeuroDebian repository
  - bash <(wget -q -O- http://neuro.debian.net/_files/neurodebian-travis.sh)
  - travis_retry sudo apt-get update -qq
  - travis_retry sudo apt-get install eatmydata  # to speedup some installations
  # install git-annex with the relevant bits
  # no recommends to avoid inheriting the entire multimedia stack
  - travis_retry sudo eatmydata apt-get install --no-install-recommends git-annex-standalone aria2 git-remote-gcrypt lsof gnupg nocache

install:
  # Install standalone build of git-annex for the recent enough version
  - travis_retry sudo eatmydata apt-get install zip pandoc
  # for metadata support
  - git config --global user.email "test@travis.land"
  - git config --global user.name "Travis Almighty"
  - cd ..; pip install -q codecov; cd -
  - pip install -r requirements.txt
  # To heal bloody scrapy -- yoh guesses that pip isn't good enough to guarantee
  # specified versioning in the depends
  - pip install --upgrade attrs
  #- pip install 'sphinx>=1.6.2'
  # So we could test under sudo -E with PATH pointing to installed location
  - sudo sed -i -e 's/^Defaults.*secure_path.*$//' /etc/sudoers

script:
  # Verify that setup.py build doesn't puke
  - python setup.py build
  # Test installation system-wide
  - sudo pip install .
  # Run tests
  # -A "$NOSE_SELECTION_OP(integration or usecase or slow)"
  - http_proxy=
    PATH=$PWD/tools/coverage-bin:$PATH
    $NOSE_WRAPPER `which nosetests` $NOSE_OPTS
      -v
      --with-doctest
      --with-cov --cover-package datalad_crawler
      --logging-level=INFO
      $TESTS_TO_PERFORM
  #- if [ ! "${DATALAD_LOG_LEVEL:-}" = 2 ]; then
  #      PYTHONPATH=$PWD $NOSE_WRAPPER make -C docs html doctest;
  #  fi
  # Report WTF information using system wide installed version
  - datalad wtf

after_success:
  - coverage combine -a /tmp/.coverage-entrypoints-*
  - codecov
